{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b8e1206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing_extensions import TypedDict, List, Optional, Union,Annotated,Sequence\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.messages import BaseMessage,ToolMessage,SystemMessage\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.graph import StateGraph,END\n",
    "from langgraph.prebuilt import  ToolNode\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e04d191",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abd24bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def supervisor(state:StateGraph)-> StateGraph:\n",
    "    \"\"\"\n",
    "    This function is a placeholder for the supervisor functionality.\n",
    "    It currently does nothing but can be expanded in the future.\n",
    "    \"\"\"\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def medicine_agent(state:StateGraph) -> StateGraph:\n",
    "    \"\"\"\n",
    "    This function is a placeholder for the medicine agent functionality.\n",
    "    It currently does nothing but can be expanded in the future.\n",
    "    \"\"\"\n",
    "    return state    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd31d1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def appointment_scheduler(state:StateGraph) -> StateGraph:\n",
    "    \"\"\"\n",
    "    This function is a placeholder for the appointment scheduler functionality.\n",
    "    It currently does nothing but can be expanded in the future.\n",
    "    \"\"\"\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bf7775f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def case_generator(state:StateGraph) -> StateGraph:\n",
    "    \"\"\"\n",
    "    This function is a placeholder for the case generator functionality.\n",
    "    It currently does nothing but can be expanded in the future.\n",
    "    \"\"\"\n",
    "    return state    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cc21da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataverification(state:StateGraph) -> StateGraph:\n",
    "    \"\"\"\n",
    "    This function is a placeholder for the data verification functionality.\n",
    "    It currently does nothing but can be expanded in the future.\n",
    "    \"\"\"\n",
    "    return state    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073a9909",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ef2dde6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'state' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m workflow \u001b[38;5;241m=\u001b[39m StateGraph(\n\u001b[1;32m      2\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStateGraph\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA graph representing the state of the system.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m----> 4\u001b[0m     initial_state\u001b[38;5;241m=\u001b[39m\u001b[43mstate\u001b[49m,\n\u001b[1;32m      5\u001b[0m     final_states\u001b[38;5;241m=\u001b[39m[next_state],\n\u001b[1;32m      6\u001b[0m     on_enter\u001b[38;5;241m=\u001b[39mon_enter,\n\u001b[1;32m      7\u001b[0m     on_exit\u001b[38;5;241m=\u001b[39mon_exit\n\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'state' is not defined"
     ]
    }
   ],
   "source": [
    "workflow = StateGraph(\n",
    "    name=\"StateGraph\",\n",
    "    description=\"A graph representing the state of the system.\",\n",
    "    initial_state=state,\n",
    "    final_states=[next_state],\n",
    "    on_enter=on_enter,\n",
    "    on_exit=on_exit\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3f5d94",
   "metadata": {},
   "source": [
    "### Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3116eef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage],add_messages]   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc1f646b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def add(a:int,b:int):\n",
    "    \"\"\"This tools add two numbers a and b\"\"\"\n",
    "    return a + b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c92d1407",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7f26acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    ).bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a593eb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17936abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_call(state:AgentState) -> AgentState:\n",
    "    system_prompt = SystemMessage(\n",
    "        content=\"You are a helpful assistant that answers questions based on the provided messages and tools\"\n",
    "    )\n",
    "    # Initialize the state with the system message if not already present\n",
    "    response = model.invoke([system_prompt]+ state[\"messages\"])\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "415900d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_continue(state:AgentState):\n",
    "    message = state['messages']\n",
    "    last_message = message[-1] \n",
    "\n",
    "    if not last_message.tool_calls:\n",
    "        return \"end\"\n",
    "    else:\n",
    "        return \"continue\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8617b80c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7ff066b95e10>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = StateGraph(AgentState)\n",
    "graph.add_node(\"our_agent\", model_call)\n",
    "\n",
    "tool_node = ToolNode(tools = tools)\n",
    "graph.add_node(\"tools\",tool_node)\n",
    "graph.set_entry_point(\"our_agent\")\n",
    "\n",
    "graph.add_conditional_edges(\"our_agent\",should_continue,\n",
    "                            {\n",
    "                                \"continue\": \"tools\",\n",
    "                                \"end\": END\n",
    "                            })\n",
    "\n",
    "graph.add_edge(\"tools\", \"our_agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5cceb833",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97edf749",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stream(stream):\n",
    "    for s in stream:\n",
    "        message = s['messages'][-1]\n",
    "        if isinstance(message, tuple):\n",
    "            print(message)\n",
    "        else:\n",
    "            message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "955c7759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "add 3+22, tell me a joke\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (b8801d66-a336-4f7e-9ff4-425f6369fe1e)\n",
      " Call ID: b8801d66-a336-4f7e-9ff4-425f6369fe1e\n",
      "  Args:\n",
      "    b: 22.0\n",
      "    a: 3.0\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: add\n",
      "\n",
      "25\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Why don't scientists trust atoms? \n",
      "\n",
      "Because they make up everything!\n"
     ]
    }
   ],
   "source": [
    "inputs = {\n",
    "    \"messages\": [(\"user\",\"add 3+22, tell me a joke\")]\n",
    "}\n",
    "print_stream(app.stream(inputs, stream_mode=\"values\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca808324",
   "metadata": {},
   "source": [
    "# Graph IV\n",
    "- Agent for creating documents and verify from the human, when the  verification is done the flow will terminate/exit \n",
    "    * after the execution of the tool , the tool will not send the toolMessage to the llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c00394d",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_content = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0204a995",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def update(content: str) -> str:\n",
    "    \"\"\"\n",
    "    updates the document content with the provided content.\n",
    "    \"\"\"\n",
    "    global document_content\n",
    "    document_content = content + \"\\n\"\n",
    "    return f\"Document updated successfully.The current content is:\\n{document_content}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65a631e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def save(filename: str) -> str:\n",
    "    \"\"\"\n",
    "    Saves the current document content to a text file and finish the process.\n",
    "    Args:\n",
    "        filename (str): The name of the file to save the content to.\n",
    "    \"\"\"\n",
    "    global document_content\n",
    "\n",
    "    # Ensure document_content is defined\n",
    "    if \"document_content\" not in globals():\n",
    "        document_content = \"\"\n",
    "\n",
    "    if not filename.endswith('.txt'):\n",
    "        filename = f'{filename}.txt'\n",
    "    try:\n",
    "        with open(filename, 'w') as file:\n",
    "            print(\"--------------------------------------inside save function ----------------------------------------------------\")\n",
    "            print(f\"\\n{document_content}\\n\")\n",
    "            print(\"--------------------------------------inside save function ----------------------------------------------------\")\n",
    "            file.write(document_content)\n",
    "        print(f\"\\n Document saved to {filename}\")\n",
    "        return f\"Document saved to {filename}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error saving document: {str(e)}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e0fef2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools1 = [ update, save]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ee241a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-genai in /home/tejas.raval@simform.dom/Desktop/ViniGraph/pheonix/lib/python3.10/site-packages (1.19.0)\n",
      "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /home/tejas.raval@simform.dom/Desktop/ViniGraph/pheonix/lib/python3.10/site-packages (from google-genai) (15.0.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /home/tejas.raval@simform.dom/Desktop/ViniGraph/pheonix/lib/python3.10/site-packages (from google-genai) (2.11.5)\n",
      "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /home/tejas.raval@simform.dom/Desktop/ViniGraph/pheonix/lib/python3.10/site-packages (from google-genai) (4.9.0)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in /home/tejas.raval@simform.dom/Desktop/ViniGraph/pheonix/lib/python3.10/site-packages (from google-genai) (4.14.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /home/tejas.raval@simform.dom/Desktop/ViniGraph/pheonix/lib/python3.10/site-packages (from google-genai) (2.32.3)\n",
      "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /home/tejas.raval@simform.dom/Desktop/ViniGraph/pheonix/lib/python3.10/site-packages (from google-genai) (0.28.1)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /home/tejas.raval@simform.dom/Desktop/ViniGraph/pheonix/lib/python3.10/site-packages (from google-genai) (2.40.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/tejas.raval@simform.dom/Desktop/ViniGraph/pheonix/lib/python3.10/site-packages (from anyio<5.0.0,>=4.8.0->google-genai) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /home/tejas.raval@simform.dom/Desktop/ViniGraph/pheonix/lib/python3.10/site-packages (from anyio<5.0.0,>=4.8.0->google-genai) (3.10)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/tejas.raval@simform.dom/Desktop/ViniGraph/pheonix/lib/python3.10/site-packages (from anyio<5.0.0,>=4.8.0->google-genai) (1.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/tejas.raval@simform.dom/Desktop/ViniGraph/pheonix/lib/python3.10/site-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (4.9.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/tejas.raval@simform.dom/Desktop/ViniGraph/pheonix/lib/python3.10/site-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (0.4.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/tejas.raval@simform.dom/Desktop/ViniGraph/pheonix/lib/python3.10/site-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (5.5.2)\n",
      "Requirement already satisfied: httpcore==1.* in /home/tejas.raval@simform.dom/Desktop/ViniGraph/pheonix/lib/python3.10/site-packages (from httpx<1.0.0,>=0.28.1->google-genai) (1.0.9)\n",
      "Requirement already satisfied: certifi in /home/tejas.raval@simform.dom/Desktop/ViniGraph/pheonix/lib/python3.10/site-packages (from httpx<1.0.0,>=0.28.1->google-genai) (2025.4.26)\n",
      "Requirement already satisfied: h11>=0.16 in /home/tejas.raval@simform.dom/Desktop/ViniGraph/pheonix/lib/python3.10/site-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/tejas.raval@simform.dom/Desktop/ViniGraph/pheonix/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/tejas.raval@simform.dom/Desktop/ViniGraph/pheonix/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/tejas.raval@simform.dom/Desktop/ViniGraph/pheonix/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/tejas.raval@simform.dom/Desktop/ViniGraph/pheonix/lib/python3.10/site-packages (from requests<3.0.0,>=2.28.1->google-genai) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/tejas.raval@simform.dom/Desktop/ViniGraph/pheonix/lib/python3.10/site-packages (from requests<3.0.0,>=2.28.1->google-genai) (2.4.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /home/tejas.raval@simform.dom/Desktop/ViniGraph/pheonix/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-genai) (0.6.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install google-genai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "255495b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of models that support generateContent:\n",
      "\n",
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-pro-vision\n",
      "models/gemini-1.5-pro-latest\n",
      "models/gemini-1.5-pro-001\n",
      "models/gemini-1.5-pro-002\n",
      "models/gemini-1.5-pro\n",
      "models/gemini-1.5-flash-latest\n",
      "models/gemini-1.5-flash-001\n",
      "models/gemini-1.5-flash-001-tuning\n",
      "models/gemini-1.5-flash\n",
      "models/gemini-1.5-flash-002\n",
      "models/gemini-1.5-flash-8b\n",
      "models/gemini-1.5-flash-8b-001\n",
      "models/gemini-1.5-flash-8b-latest\n",
      "models/gemini-2.5-pro-exp-03-25\n",
      "models/gemini-2.5-pro-preview-03-25\n",
      "models/gemini-2.5-flash-preview-04-17\n",
      "models/gemini-2.5-flash-preview-05-20\n",
      "models/gemini-2.5-flash-preview-04-17-thinking\n",
      "models/gemini-2.5-pro-preview-05-06\n",
      "models/gemini-2.5-pro-preview-06-05\n",
      "models/gemini-2.0-flash-exp\n",
      "models/gemini-2.0-flash\n",
      "models/gemini-2.0-flash-001\n",
      "models/gemini-2.0-flash-exp-image-generation\n",
      "models/gemini-2.0-flash-lite-001\n",
      "models/gemini-2.0-flash-lite\n",
      "models/gemini-2.0-flash-preview-image-generation\n",
      "models/gemini-2.0-flash-lite-preview-02-05\n",
      "models/gemini-2.0-flash-lite-preview\n",
      "models/gemini-2.0-pro-exp\n",
      "models/gemini-2.0-pro-exp-02-05\n",
      "models/gemini-exp-1206\n",
      "models/gemini-2.0-flash-thinking-exp-01-21\n",
      "models/gemini-2.0-flash-thinking-exp\n",
      "models/gemini-2.0-flash-thinking-exp-1219\n",
      "models/gemini-2.5-flash-preview-tts\n",
      "models/gemini-2.5-pro-preview-tts\n",
      "models/learnlm-2.0-flash-experimental\n",
      "models/gemma-3-1b-it\n",
      "models/gemma-3-4b-it\n",
      "models/gemma-3-12b-it\n",
      "models/gemma-3-27b-it\n",
      "models/gemma-3n-e4b-it\n",
      "List of models that support embedContent:\n",
      "\n",
      "models/embedding-001\n",
      "models/text-embedding-004\n",
      "models/gemini-embedding-exp-03-07\n",
      "models/gemini-embedding-exp\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "print(\"List of models that support generateContent:\\n\")\n",
    "for m in client.models.list():\n",
    "    for action in m.supported_actions:\n",
    "        if action == \"generateContent\":\n",
    "            print(m.name)\n",
    "\n",
    "print(\"List of models that support embedContent:\\n\")\n",
    "for m in client.models.list():\n",
    "    for action in m.supported_actions:\n",
    "        if action == \"embedContent\":\n",
    "            print(m.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "facbcb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash-lite\",\n",
    "    ).bind_tools(tools1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0c5d07c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_agent(state:AgentState) -> AgentState:\n",
    "    \n",
    "    system_prompt = SystemMessage( \n",
    "        content=f\"\"\"\n",
    "        You are a Drafter, a helpful writing assistant. You are going to help the user update and save documents based on the provided messages and tools\n",
    "            - If the user wants to update or modify content,use the 'update' tool with the complete updated content.\n",
    "            - If the user wants to save and finish , you need to use the 'save' tool.\n",
    "            - make sure to always show the current document state after modifications.\n",
    "            - here are your tools  {tools1}\n",
    "            \n",
    "            The current docuement content is:{document_content}\n",
    "            \"\"\"\n",
    "    )\n",
    "    if not state[\"messages\"]:\n",
    "        user_input = \"I'm ready to help you update a document. What would you like to create? \"\n",
    "        user_message = HumanMessage(content=user_input)\n",
    "\n",
    "\n",
    "    else:\n",
    "        user_input = input(\"\\nWhat would you like to do with the document?\")\n",
    "        print(f\"\\nUser: {user_input}\")\n",
    "        user_message = HumanMessage(content=user_input)\n",
    "\n",
    "    all_messages = list(state[\"messages\"]) + [user_message] + [system_prompt]\n",
    "    response = model1.invoke(all_messages)\n",
    "\n",
    "\n",
    "    print(f\"\\nAssistant: {response.content}\")\n",
    "    # Only check tool_calls if response is an AIMessage\n",
    "    if isinstance(response, AIMessage) and getattr(response, 'tool_calls', None):\n",
    "        print(f\"Using tools:{[tc['name'] for tc in response.tool_calls]}\")\n",
    "    return {\"messages\": list(state[\"messages\"]) + [user_message, response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "04fa3715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_continue_doc(state:AgentState) -> str:\n",
    "    \"\"\" Determines whether we should continue or end the conversation.\"\"\"\n",
    "    messages = state['messages']\n",
    "    if not messages:\n",
    "        return \"continue\"\n",
    "    \n",
    "    for message in reversed(messages):\n",
    "        if (\n",
    "            isinstance(message, ToolMessage)\n",
    "            and \"saved\" in message.content.lower()# type: ignore\n",
    "            and \"document\" in message.content.lower()# type: ignore\n",
    "        ):\n",
    "            return \"end\"\n",
    "        \n",
    "    return \"continue\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5c662a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_messages(messages):\n",
    "\n",
    "    \"\"\"Function I made  to print the messages in t a more readable format\"\"\"\n",
    "\n",
    "    if not messages:\n",
    "        print(\"No messages to display.\")\n",
    "        return\n",
    "\n",
    "    for message in messages[-3:]:\n",
    "        if isinstance(message, ToolMessage):\n",
    "            print(f\"\\n TOOL RESULT: {message.content}\")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9809cabd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7ff0506bf7f0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph1 = StateGraph(AgentState)\n",
    "\n",
    "graph1.add_node(\"doc_agent\", doc_agent)\n",
    "graph1.add_node(\"tools\",ToolNode(tools=tools1))\n",
    "\n",
    "graph1.set_entry_point(\"doc_agent\")\n",
    "graph1.add_edge(\"doc_agent\", \"tools\")\n",
    "\n",
    "graph1.add_conditional_edges(\"tools\",\n",
    "                              should_continue_doc,\n",
    "                            {\n",
    "                                \"continue\": \"doc_agent\",\n",
    "                                \"end\": END\n",
    "                            },)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f1b1444b",
   "metadata": {},
   "outputs": [],
   "source": [
    "app1 = graph1.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ac22099d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_document_agent():\n",
    "    print(\"\\n ================== Document Agent ================\\n\")\n",
    "    \n",
    "    state = {\"messages\": []}\n",
    "\n",
    "    for step in app1.stream(state, stream_mode=\"values\"):\n",
    "        if \"messages\" in step:\n",
    "            print_messages(step[\"messages\"])\n",
    "    print(\"\\n======================DRAFTER FINISHED=======================.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9603b542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ================== Document Agent ================\n",
      "\n",
      "No messages to display.\n",
      "\n",
      "Assistant: Okay, I'm ready. Please provide the content for the document.\n",
      "\n",
      "User: work from home\n",
      "\n",
      "Assistant: \n",
      "Using tools:['update']\n",
      "\n",
      " TOOL RESULT: Document updated successfully.The current content is:\n",
      "work from home\n",
      "\n",
      "\n",
      "User: update\n",
      "\n",
      "Assistant: Okay. Is there anything else you would like to add or modify?\n",
      "\n",
      " TOOL RESULT: Document updated successfully.The current content is:\n",
      "work from home\n",
      "\n",
      "\n",
      " TOOL RESULT: Document updated successfully.The current content is:\n",
      "work from home\n",
      "\n",
      "\n",
      "User: add the work flie balance\n",
      "\n",
      "Assistant: \n",
      "Using tools:['update']\n",
      "\n",
      " TOOL RESULT: Document updated successfully.The current content is:\n",
      "work from home\n",
      "work flie balance\n",
      "\n",
      "\n",
      "User: save\n",
      "\n",
      "Assistant: OK. What would you like to name the file?\n",
      "\n",
      " TOOL RESULT: Document updated successfully.The current content is:\n",
      "work from home\n",
      "work flie balance\n",
      "\n",
      "\n",
      " TOOL RESULT: Document updated successfully.The current content is:\n",
      "work from home\n",
      "work flie balance\n",
      "\n",
      "\n",
      "User: save the document\n",
      "\n",
      "Assistant: I need a file name to save the document. What would you like to name it?\n",
      "\n",
      "User: save the document\n",
      "\n",
      "Assistant: I am ready to save the document, but I need a file name. What would you like to name it?\n",
      "\n",
      "User: save \n",
      "\n",
      "Assistant: I am unable to save the document without a file name. Can you please provide a file name?\n",
      "\n",
      "User: save \n",
      "\n",
      "Assistant: I am still unable to save the document. I need a file name. Can you please provide one?\n",
      "\n",
      "User:  i want to save it\n",
      "\n",
      "Assistant: I am programmed to save the document, but I need a file name to do so. What would you like to name the file?\n",
      "\n",
      "User: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tejas.raval@simform.dom/Desktop/ViniGraph/pheonix/lib/python3.10/site-packages/langchain_google_genai/chat_models.py:1568: UserWarning: HumanMessage with empty content was removed to prevent API error\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Assistant: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrun_document_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[31], line 6\u001b[0m, in \u001b[0;36mrun_document_agent\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m ================== Document Agent ================\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m state \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: []}\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m app1\u001b[38;5;241m.\u001b[39mstream(state, stream_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m step:\n\u001b[1;32m      8\u001b[0m         print_messages(step[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/Desktop/ViniGraph/pheonix/lib/python3.10/site-packages/langgraph/pregel/__init__.py:2436\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[0m\n\u001b[1;32m   2434\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mmatch_cached_writes():\n\u001b[1;32m   2435\u001b[0m             loop\u001b[38;5;241m.\u001b[39moutput_writes(task\u001b[38;5;241m.\u001b[39mid, task\u001b[38;5;241m.\u001b[39mwrites, cached\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 2436\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[1;32m   2437\u001b[0m             [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t\u001b[38;5;241m.\u001b[39mwrites],\n\u001b[1;32m   2438\u001b[0m             timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[1;32m   2439\u001b[0m             get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[1;32m   2440\u001b[0m             schedule_task\u001b[38;5;241m=\u001b[39mloop\u001b[38;5;241m.\u001b[39maccept_push,\n\u001b[1;32m   2441\u001b[0m         ):\n\u001b[1;32m   2442\u001b[0m             \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[1;32m   2443\u001b[0m             \u001b[38;5;28;01myield from\u001b[39;00m output()\n\u001b[1;32m   2444\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/ViniGraph/pheonix/lib/python3.10/site-packages/langgraph/pregel/runner.py:161\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[0m\n\u001b[1;32m    159\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 161\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m                \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/Desktop/ViniGraph/pheonix/lib/python3.10/site-packages/langgraph/pregel/retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     38\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     42\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[0;32m~/Desktop/ViniGraph/pheonix/lib/python3.10/site-packages/langgraph/utils/runnable.py:623\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[1;32m    622\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[0;32m--> 623\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    625\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/Desktop/ViniGraph/pheonix/lib/python3.10/site-packages/langgraph/utils/runnable.py:377\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    375\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(ret)\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 377\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[0;32mIn[26], line 20\u001b[0m, in \u001b[0;36mdoc_agent\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m     16\u001b[0m     user_message \u001b[38;5;241m=\u001b[39m HumanMessage(content\u001b[38;5;241m=\u001b[39muser_input)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 20\u001b[0m     user_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mWhat would you like to do with the document?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mUser: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muser_input\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     22\u001b[0m     user_message \u001b[38;5;241m=\u001b[39m HumanMessage(content\u001b[38;5;241m=\u001b[39muser_input)\n",
      "File \u001b[0;32m~/Desktop/ViniGraph/pheonix/lib/python3.10/site-packages/ipykernel/kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1280\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/ViniGraph/pheonix/lib/python3.10/site-packages/ipykernel/kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1323\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1324\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "run_document_agent()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f6257e",
   "metadata": {},
   "source": [
    "# Graph V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fe7fb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cebab12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7809e143",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pheonix",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
